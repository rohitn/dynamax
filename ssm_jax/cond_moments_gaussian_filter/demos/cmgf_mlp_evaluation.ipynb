{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzeh8LgE0KQ3"
      },
      "source": [
        "#CMGF-EKF Evaluation for MLP Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo0q-V7r1Rlk"
      },
      "source": [
        "Author: Peter Chang([@petergchang](https://github.com/petergchang))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpeCZrrr1VT8"
      },
      "source": [
        "##0. Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Jt8tn_d8zxq1"
      },
      "outputs": [],
      "source": [
        "# Silence WARNING:root:The use of `check_types` is deprecated and does not have any effect.\n",
        "# https://github.com/tensorflow/probability/issues/1523\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "class CheckTypesFilter(logging.Filter):\n",
        "    def filter(self, record):\n",
        "        return \"check_types\" not in record.getMessage()\n",
        "\n",
        "\n",
        "logger.addFilter(CheckTypesFilter())\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oKLE1L7F0I-4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "installing ssm_jax\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from ssm_jax.cond_moments_gaussian_filter.inference import *\n",
        "    from ssm_jax.cond_moments_gaussian_filter.containers import *\n",
        "    import flax.linen as nn\n",
        "except ModuleNotFoundError:\n",
        "    print('installing ssm_jax')\n",
        "    %pip install -qq git+https://github.com/probml/ssm-jax.git\n",
        "    %pip install -qq flax\n",
        "    from ssm_jax.cond_moments_gaussian_filter.inference import *\n",
        "    from ssm_jax.cond_moments_gaussian_filter.containers import *\n",
        "    import flax.linen as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EDo2iwuE1Tct"
      },
      "outputs": [],
      "source": [
        "from typing import Sequence\n",
        "from functools import partial\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "import matplotlib.cm as cm\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "from jax.flatten_util import ravel_pytree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDyP-txo1epD"
      },
      "source": [
        "#1. MLP Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Y-eMPyrA26RL"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    features: Sequence[int]\n",
        "\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        for feat in self.features[:-1]:\n",
        "            x = nn.relu(nn.Dense(feat)(x))\n",
        "        x = nn.Dense(self.features[-1])(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "unFLKgX929K2"
      },
      "outputs": [],
      "source": [
        "def get_mlp_flattened_params(model_dims, key=0):\n",
        "    if isinstance(key, int):\n",
        "        key = jr.PRNGKey(key)\n",
        "\n",
        "    # Define MLP model\n",
        "    input_dim, features = model_dims[0], model_dims[1:]\n",
        "    model = MLP(features)\n",
        "    dummy_input = jnp.ones((input_dim,))\n",
        "\n",
        "    # Initialize parameters using dummy input\n",
        "    params = model.init(key, dummy_input)\n",
        "    flat_params, unflatten_fn = ravel_pytree(params)\n",
        "\n",
        "    # Define apply function\n",
        "    def apply(flat_params, x, model, unflatten_fn):\n",
        "        return model.apply(unflatten_fn(flat_params), jnp.atleast_1d(x))\n",
        "\n",
        "    apply_fn = partial(apply, model=model, unflatten_fn=unflatten_fn)\n",
        "\n",
        "    return model, flat_params, unflatten_fn, apply_fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "n4c6sV4U290N"
      },
      "outputs": [],
      "source": [
        "def separate_flat_params(model_dims):\n",
        "    assert len(model_dims) > 1\n",
        "    separate_params = []\n",
        "    curr_idx = 0\n",
        "    for layer in range(1, len(model_dims)):\n",
        "        # Number of parameter elements corresponding to current layer\n",
        "        num_prev, num_curr = model_dims[layer-1], model_dims[layer] # Number of nodes in prev, curr layer\n",
        "        num_bias_params = num_curr\n",
        "        num_weight_params = num_prev * num_curr\n",
        "        num_params_curr_layer = num_bias_params + num_weight_params\n",
        "        \n",
        "        # Range of indices in flattened params array corresponding to current layer\n",
        "        idx_range = jnp.arange(curr_idx, curr_idx + num_params_curr_layer)\n",
        "        \n",
        "        # Append list of indices for each node in current layer\n",
        "        separate_params += [jnp.array([idx_range[i + num_curr * j] for j in range(num_prev + 1)]) for i in range(num_curr)]\n",
        "        \n",
        "        curr_idx += num_params_curr_layer\n",
        "    \n",
        "    # Function to aggregate separated params list \n",
        "    def aggregate_fn(separate_params, model_dims):\n",
        "        assert len(model_dims) > 1\n",
        "        aggregate_params_list = []\n",
        "        curr_idx = 0\n",
        "        for layer in range(1, len(model_dims)):\n",
        "            # Flatten params sublist corresponding to each layer\n",
        "            aggregate_params_list.append(jnp.ravel(jnp.array(separate_params[curr_idx:curr_idx + model_dims[layer]]), order='F'))\n",
        "            curr_idx += model_dims[layer]\n",
        "            \n",
        "        return jnp.concatenate(aggregate_params_list)\n",
        "    \n",
        "    return separate_params, partial(aggregate_fn, model_dims = model_dims)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('.venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "318f4a281a9045fa754c1e6daf91d23ec39e886b252f1bbccc2b4e9f6d70b1b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
